{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c1adfaf77cb0418bb61a4e36207e473d"}}, "metadata": {}}, {"output_type": "stream", "text": "The code failed because of a fatal error:\n\tError sending http request and maximum retry encountered..\n\nSome things to try:\na) Make sure Spark has enough available resources for Jupyter to create a Spark context.\nb) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\nc) Restart the kernel.\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e24284888ece4da4b1c6d43b9c11c57f"}}, "metadata": {}}, {"output_type": "stream", "text": "The code failed because of a fatal error:\n\tError sending http request and maximum retry encountered..\n\nSome things to try:\na) Make sure Spark has enough available resources for Jupyter to create a Spark context.\nb) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\nc) Restart the kernel.\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from pyspark.sql.types import StructType, StructField\nfrom pyspark.sql.types import  IntegerType,StringType,DecimalType,LongType,DoubleType\n\nsong_schema = StructType([\n    StructField('artist_id',StringType()),  \n    StructField('artist_latitude',DoubleType()),\n    StructField('artist_location',StringType()),\n    StructField('artist_longitude',DoubleType()),\n    StructField('artist_name',StringType()),\n    StructField('duration',DoubleType()),\n    StructField('num_songs' ,IntegerType()),\n    StructField('song_id',StringType()),\n    StructField('title',StringType()),\n    StructField('year',IntegerType())   \n])\nlog_schema = StructType([\n    StructField('artist',StringType()),\n    StructField('auth',StringType()),\n    StructField('firstName',StringType()),\n    StructField('gender',StringType()),\n    StructField('itemInSession',IntegerType()),\n    StructField('lastName',StringType()),\n    StructField('length',DoubleType()),\n    StructField('level',StringType()),\n    StructField('location',StringType()),\n    StructField('method',StringType()),\n    StructField('page',StringType()),\n    StructField('registration',StringType()),\n    StructField('sessionId',IntegerType()),    \n    StructField('song',StringType()),\n    StructField('status',IntegerType()),\n    StructField('ts',LongType()),\n    StructField('userAgent',StringType()),\n    StructField('userId',StringType())\n    \n])\ndf_song = spark.read.json(\"s3a://udacity-dend/song_data/*/*/*\",schema=song_schema)\ndf_log = spark.read.json(\"s3a://udacity-dend/log_data/*/*/*.json\",schema=log_schema)\n\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import TimestampType\nfrom pyspark.sql.functions import to_timestamp\ndim_user_columns = ['userid','firstname','lastName','gender','level']\ndim_song_columns = ['song_id','artist_id','duration','title','year']\ndim_user = df_log.selectExpr(*dim_user_columns).dropDuplicates().filter(col('userid').isNotNull()) \ndim_song = df_song.selectExpr(*dim_song_columns).dropDuplicates() \ndf_log.selectExpr(\"cast(ts/1000 as timestamp) as time\").alias('time').createOrReplaceTempView(\"time_table\")\ndim_time = spark.sql(\"select DISTINCT time, hour(time) as hour, day(time) as day,weekofyear(time) as week,\\\n          month(time) as month,year(time) as year,date_format(time, 'EEEE') as weekday  FROM time_table\")\ndim_artist_columns = ['artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude']\ndim_artist =  df_song.selectExpr(*dim_artist_columns).dropDuplicates()\n\n#####################################\ndim_user.show(n=5)\ndim_song.show(n=5)\ndim_time.show(n=5)\ndim_artist.show(n=5)", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "df5b4b1fe1764121957cce1efb12f0f7"}}, "metadata": {}}, {"output_type": "stream", "text": "The code failed because of a fatal error:\n\tError sending http request and maximum retry encountered..\n\nSome things to try:\na) Make sure Spark has enough available resources for Jupyter to create a Spark context.\nb) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\nc) Restart the kernel.\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}